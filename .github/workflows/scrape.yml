name: Scrape & Index Albums

on:
  schedule:
    - cron: "0 */6 * * *"   # every 6 hours
  workflow_dispatch:
    inputs:
      max_albums:
        description: "Max new albums to index per run (default 300)"
        required: false
        default: "300"

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run scraper
        env:
          MAX_ALBUMS: ${{ github.event.inputs.max_albums || '300' }}
          REQUEST_DELAY: "1.5"
        run: python scraper.py

      - name: Generate RSS feed
        run: python generate_rss.py

      - name: Commit results
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add albums.json feed.xml
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            TOTAL=$(python -c "import json; d=json.load(open('albums.json')); print(d['meta']['total'])")
            NEW=$(python -c "import json; d=json.load(open('albums.json')); print(d['meta']['new_this_run'])")
            git commit -m "index: ${TOTAL} albums (+${NEW} new) [skip ci]"
            git push
          fi
