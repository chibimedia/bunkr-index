name: Scrape & Index Albums

on:
  schedule:
    # Every 6 hours
    - cron: "0 */6 * * *"
  workflow_dispatch:
    inputs:
      max_albums:
        description: "Max new albums to index per run"
        required: false
        default: "500"

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run scraper
        env:
          MAX_ALBUMS: ${{ github.event.inputs.max_albums || '500' }}
          REQUEST_DELAY: "1.5"
        run: python scraper.py

      - name: Generate RSS feed
        run: python generate_rss.py

      - name: Commit updated albums.json & feed.xml
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add albums.json feed.xml
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            TOTAL=$(python -c "import json; d=json.load(open('albums.json')); print(d['meta']['total'])")
            NEW=$(python -c "import json; d=json.load(open('albums.json')); print(d['meta']['new_this_run'])")
            git commit -m "chore: index update â€” ${TOTAL} total, +${NEW} new [skip ci]"
            git push
          fi
